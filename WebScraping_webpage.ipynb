{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWPKq27IQLMIzzEjGJ8WCv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gbQnoU2MMjf4"},"outputs":[],"source":["# This block throws many errors like [CONSOLE]. â„¹ Console error: Cannot redefine property: webdriver\n","# Does not affect final output. That's Playwright throwing some errors while scraping webpage\n","async def web_scraping_webpage(url, magic = True, simulate_user = True):\n","    browser_config = BrowserConfig(\n","        browser_type=\"chromium\",  # Options: \"chromium\", \"firefox\", \"webkit\"\n","        headless=True,            # Set to False if you want to see the browser window\n","        viewport_width=1280,\n","        viewport_height=800,\n","        verbose=True,\n","        user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n","    )\n","    async with AsyncWebCrawler(config=browser_config) as crawler:\n","        crawler_config = CrawlerRunConfig(\n","            screenshot=False,\n","            verbose=True,\n","            cache_mode=CacheMode.DISABLED,\n","            wait_until='domcontentloaded',\n","            delay_before_return_html = 5,\n","            log_console=True,\n","            exclude_social_media_links=True,\n","            # exclude_external_links = True,\n","            exclude_external_images  =True,\n","            magic=magic,\n","            simulate_user=simulate_user,\n","            scan_full_page=True,  # Tells the crawler to try scrolling the entire page\n","            scroll_delay=1,     # Delay (seconds) between scroll steps\n","        )\n","        result = None\n","        try:\n","            result = await crawler.arun(\n","                url=url,\n","                config=crawler_config\n","            )\n","        except Exception as e:\n","        # if not result.success:\n","            print(f\"Crawl Exception: {e}\")\n","        if result is None or not getattr(result, 'markdown', None):\n","            print(f\"Crawl failed or no markdown for {url}\")\n","            return ['URL not found']\n","\n","        # print(result.markdown)\n","        return result.markdown\n","        # print(lines)\n","        # print(result.html)\n","\n","\n","\n","nest_asyncio.apply()\n","\n","async def get_ingredient_list(user_query):\n","  url = get_webpage_url(user_query)\n","  ingredient_list_str = \"\"\n","  # url = get_webpage_url(\"Super Cream With Sunscreen SPF 30\")\n","  print(url)\n","  # url = \"https://incidecoder.com/products/olay-super-cream-with-sunscreen-spf-30\"\n","  # url = \"https://www.skinsafeproducts.com/l-oreal-paris-colour-riche-lipstick-mica-0-13-oz\"\n","  if \"incidecoder.com\" in url:\n","      processed_rows = asyncio.run(web_scraping_webpage(url, magic = True, simulate_user = True))\n","      # print(processed_rows)\n","      parts = str(processed_rows).split(\"## Ingredients overview\")\n","      # print(parts[0])\n","      if \"[less]\" in parts[1]:\n","          ingredient_list_with_description = parts[1].split(\"[less]\")[0]\n","      else: ingredient_list_with_description = \"\"\n","      matches = re.findall(r'\\[(.*?)\\]', ingredient_list_with_description)\n","      ingredient_list_wo_description = []\n","      i = 0\n","      for each_ingredient in matches:\n","          ingredient_list_wo_description.append((str(i+1) + \":\" + each_ingredient))\n","          i += 1\n","      ingredient_list_str = \"\"\n","      print(f\"There are a total of {i} ingredients, as listed on INCIdecoder: \\n\")\n","      ingredient_list_str += f\"There are a total of {i} ingredients, as listed on INCIdecoder: \\n\"\n","\n","      for each_ingredient in ingredient_list_wo_description:\n","          print(f\"{str(each_ingredient)} \")\n","          ingredient_list_str += f\"{str(each_ingredient)}\\n\"\n","  else:\n","      print(f\"Visit {url} to read ingredients list.\")\n","      ingredient_list_str += f\"Visit {url} to read ingredients list.\"\n","  return ingredient_list_str\n","# await get_ingredient_list(\"The Body Shop Camomile Sumptuous Cleansing Butter\")"]}]}