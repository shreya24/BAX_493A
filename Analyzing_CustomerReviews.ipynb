{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpJqr2XFjZbOhDZZ4CDw8t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dg-gb9zvRh2Z"},"outputs":[],"source":["def generate_responseOpenAI(prompt):\n","    OPENAI_MODEL = \"gpt-4o\"\n","    OPENAI_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n","    OPENAI_API_KEY = \"abc\"\n","\n","    session = requests.Session()\n","    headers = {\n","        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n","        \"Content-Type\": \"application/json\"\n","    }\n","    \"\"\"Use OpenAI GPT-4o via direct HTTP request to generate a response\"\"\"\n","    payload = {\n","        \"model\": OPENAI_MODEL,\n","        \"messages\": [\n","            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes topics.\"},\n","            {\"role\": \"user\", \"content\": prompt}\n","        ],\n","        \"max_tokens\": 200,\n","        \"temperature\": 0\n","    }\n","\n","    try:\n","        response = session.post(OPENAI_ENDPOINT, headers=headers, json=payload, timeout=20)\n","        response.raise_for_status()\n","        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n","    except requests.RequestException as e:\n","        print(\"Request failed:\", e)\n","        return \"\"\n","\n","def generate_topics_from_customer_reviews(partitions, spark):\n","    TEXT_DELIMITER = '####'\n","    previous_topics_broadcast = spark.sparkContext.broadcast(set())\n","    for i, batch in enumerate(partitions, start=1):\n","        print(f\"\\nProcessing Batch {i}\")\n","\n","        previous_topics = previous_topics_broadcast.value\n","\n","        # First LLM call: Generate 5 summarized topics\n","        prompt_1 = f\"\"\"Below is a set of reviews delimited by {TEXT_DELIMITER}:\\n{batch}\\n\n","    Identify 5 summarized topics (1–4 words) from these reviews.\n","    Return the output as a bullet list, each line one concise topic. No descriptions.\"\"\"\n","\n","        text_1 = generate_responseOpenAI(prompt_1)\n","        print(\"Raw Topics Output:\", text_1)\n","\n","        extracted_topics = []\n","        for line in text_1.split(\"\\n\"):\n","            if line.strip():\n","                match = re.search(r\"[-•*]?\\s*(.+)\", line.strip())\n","                if match:\n","                    extracted_topics.append(match.group(1).strip())\n","\n","        print(\"Extracted Topics:\", extracted_topics)\n","\n","        # Second LLM call: Filter out previously seen topics\n","        prompt_2 = f\"\"\"Given the following topics:\\n{extracted_topics}\\n\n","    Previously covered topics are: {list(previous_topics)}\\n\n","    Return only the new topics not present in the previously covered list.\n","    Output as a bullet list, one topic per line, 1–4 words, no description.\"\"\"\n","\n","        text_2 = generate_responseOpenAI(prompt_2)\n","        print(\"Filtered Topics Output:\", text_2)\n","\n","        new_topics = []\n","        for line in text_2.split(\"\\n\"):\n","            if line.strip():\n","                match = re.search(r\"[-•*]?\\s*(.+)\", line.strip())\n","                if match:\n","                    topic = match.group(1).strip()\n","                    if topic:\n","                        new_topics.append(topic)\n","\n","        print(\"New Topics:\", new_topics)\n","\n","\n","        if new_topics:\n","            updated_set = previous_topics.union(set(new_topics))\n","            previous_topics_broadcast.unpersist()\n","            previous_topics_broadcast = spark.sparkContext.broadcast(updated_set)\n","\n","        print(\"Updated Unique Topics:\", previous_topics_broadcast.value)\n","        print(\"-\" * 50)\n","\n","        if i == 10: break\n","    final_topics = list(previous_topics_broadcast.value)\n","    print(\"Final Unique Topics:\", previous_topics_broadcast.value)\n","    return final_topics"]},{"cell_type":"code","source":["def create_partitions(nykaa_customer_reviews):\n","  current_partition = \"\"\n","  current_partition_length = 0\n","  partitions = []\n","\n","  for row in nykaa_customer_reviews.collect():\n","      review_length = row.review_length\n","\n","      if current_partition_length + review_length > 2000:\n","          partitions.append(current_partition)\n","          current_partition = \"\"\n","          current_partition_length = 0\n","\n","      to_add = \"####\" + row.user_review\n","      current_partition += to_add\n","      current_partition_length += review_length\n","\n","  if current_partition:\n","      partitions.append(current_partition)\n","\n","  for i, partition in enumerate(partitions):\n","      print(f\"Partition {i+1}:\\n\")\n","      print(\"\".join(partition))\n","      print(\"\\n\" + \"=\" * 50 + \"\\n\")\n","  return partitions"],"metadata":{"id":"bGXFBRV1RnPh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# when user asks for what customers are talking about the product on the internet\n","def customer_review_topic_modeling(product_name):\n","  from pyspark.sql import SparkSession\n","  spark = SparkSession.builder.appName(\"BAX493_FinalProject\")\\\n","      .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n","      .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n","      .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n","      .config(\"spark.driver.memory\", \"12g\").config(\"spark.executor.memory\", \"12g\").getOrCreate()\n","\n","  file_path = \"/content/sample_data/nyka_top_brands_cosmetics_product_reviews.csv\"\n","  # Source: https://www.kaggle.com/datasets/jithinanievarghese/cosmetics-and-beauty-products-reviews-top-brands\n","\n","  nykaa_customer_reviews = spark.read.csv(file_path, header=True, inferSchema=True)\n","\n","  nykaa_customer_reviews = nykaa_customer_reviews.select(\n","      \"brand_name\", \"review_title\", \"review_text\", \"review_rating\", \"review_label\",\n","      \"product_title\", \"mrp\", \"product_rating\", \"product_rating_count\", \"product_url\"\n","  )\n","\n","  nykaa_customer_reviews = nykaa_customer_reviews.withColumn('user_review',\n","                      concat(col('review_title'),lit('. '), col('review_text')))\n","  nykaa_customer_reviews = nykaa_customer_reviews.drop(\"review_text\", \"review_title\")\n","\n","  nykaa_customer_reviews = nykaa_customer_reviews.filter(col(\"user_review\").isNotNull())\n","  nykaa_customer_reviews = nykaa_customer_reviews.withColumn(\"review_length\", length(\"user_review\"))\n","  nykaa_customer_reviews = nykaa_customer_reviews.where(nykaa_customer_reviews.product_title==product_name)\n","  partitions = create_partitions(nykaa_customer_reviews)\n","  final_topics = generate_topics_from_customer_reviews(partitions, spark)\n","  return (partitions, final_topics)"],"metadata":{"id":"x0-Y8g5oRo1j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","from collections import Counter\n","\n","def analyze_sentiment_from_customer_reviews(partitions, spark):\n","    TEXT_DELIMITER = '####'\n","    overall_sentiment_counter = Counter()  # Track sentiment across all batches\n","\n","    for i, batch in enumerate(partitions, start=1):\n","        print(f\"\\nProcessing Batch {i}\")\n","\n","        # Prompt for sentiment analysis\n","        prompt = f\"\"\"Below is a set of customer reviews delimited by '{TEXT_DELIMITER}':\\n{batch}\\n\\n\n","For each review, assign one of the following sentiment labels: Positive, Neutral, or Negative.\n","\n","Return the results as a list, with each line containing:\n","[Sentiment]: [Original Review]\n","\n","Example:\n","Positive: I love this product!\n","Neutral: The packaging was okay.\n","Negative: It irritated my skin.\n","\n","Now, return the labeled reviews below:\"\"\"\n","\n","        text = generate_responseOpenAI(prompt)\n","        print(\"Sentiment Analysis Output:\\n\", text)\n","\n","        # Extract sentiment labels using regex\n","        sentiments = []\n","        for line in text.splitlines():\n","            match = re.match(r'^\\s*(Positive|Neutral|Negative)\\s*:', line, re.IGNORECASE)\n","            if match:\n","                sentiment = match.group(1).capitalize()\n","                sentiments.append(sentiment)\n","\n","        # Batch-level stats\n","        batch_sentiment_counter = Counter(sentiments)\n","        majority_sentiment = batch_sentiment_counter.most_common(1)[0][0] if batch_sentiment_counter else \"Unknown\"\n","        print(f\"Majority Sentiment (Batch {i}): {majority_sentiment}\")\n","        print(f\"Sentiment Counts (Batch {i}): {dict(batch_sentiment_counter)}\")\n","\n","        # Update overall sentiment tracker\n","        overall_sentiment_counter.update(batch_sentiment_counter)\n","\n","        print(\"-\" * 50)\n","\n","        if i == 10: #stopping at 10 batches here due to paucity of time. Feel free to change this to run over the entire dataset\n","            break\n","\n","    # Final overall stats\n","    overall_majority = overall_sentiment_counter.most_common(1)[0][0] if overall_sentiment_counter else \"Unknown\"\n","    print(\"\\n===== Overall Sentiment Summary =====\")\n","    print(f\"Overall Sentiment Counts: {dict(overall_sentiment_counter)}\")\n","    print(f\"Overall Majority Sentiment: {overall_majority}\")"],"metadata":{"id":"o0DO8rJjSFMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def customer_review_sentiment_modeling(product_name):\n","  from pyspark.sql import SparkSession\n","  spark = SparkSession.builder.appName(\"BAX493_FinalProject\")\\\n","      .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n","      .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n","      .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n","      .config(\"spark.driver.memory\", \"12g\").config(\"spark.executor.memory\", \"12g\").getOrCreate()\n","\n","  file_path = \"/content/sample_data/nyka_top_brands_cosmetics_product_reviews.csv\"\n","  # Source: https://www.kaggle.com/datasets/jithinanievarghese/cosmetics-and-beauty-products-reviews-top-brands\n","\n","  nykaa_customer_reviews = spark.read.csv(file_path, header=True, inferSchema=True)\n","\n","  nykaa_customer_reviews = nykaa_customer_reviews.select(\n","      \"brand_name\", \"review_title\", \"review_text\", \"review_rating\", \"review_label\",\n","      \"product_title\", \"mrp\", \"product_rating\", \"product_rating_count\", \"product_url\"\n","  )\n","\n","  nykaa_customer_reviews = nykaa_customer_reviews.withColumn('user_review',\n","                      concat(col('review_title'),lit('. '), col('review_text')))\n","  nykaa_customer_reviews = nykaa_customer_reviews.drop(\"review_text\", \"review_title\")\n","\n","  nykaa_customer_reviews = nykaa_customer_reviews.filter(col(\"user_review\").isNotNull())\n","  nykaa_customer_reviews = nykaa_customer_reviews.withColumn(\"review_length\", length(\"user_review\"))\n","  nykaa_customer_reviews = nykaa_customer_reviews.where(nykaa_customer_reviews.product_title==product_name)\n","  partitions = create_partitions(nykaa_customer_reviews)\n","  analyze_sentiment_from_customer_reviews(partitions, spark)"],"metadata":{"id":"rCNbT64BSG3d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def customer_review_topic_modeling_CoherenceScore(product_name):\n","    from pyspark.sql import SparkSession\n","    from pyspark.sql.functions import concat, col, lit, length\n","\n","    spark = SparkSession.builder.appName(\"BAX493_FinalProject\")\\\n","        .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n","        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n","        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n","        .config(\"spark.driver.memory\", \"12g\").config(\"spark.executor.memory\", \"12g\").getOrCreate()\n","\n","    file_path = \"/content/sample_data/nyka_top_brands_cosmetics_product_reviews.csv\"\n","\n","    nykaa_customer_reviews = spark.read.csv(file_path, header=True, inferSchema=True)\n","\n","    nykaa_customer_reviews = nykaa_customer_reviews.select(\n","        \"brand_name\", \"review_title\", \"review_text\", \"review_rating\", \"review_label\",\n","        \"product_title\", \"mrp\", \"product_rating\", \"product_rating_count\", \"product_url\"\n","    )\n","\n","    nykaa_customer_reviews = nykaa_customer_reviews.withColumn('user_review',\n","                        concat(col('review_title'), lit('. '), col('review_text')))\n","    nykaa_customer_reviews = nykaa_customer_reviews.drop(\"review_text\", \"review_title\")\n","    nykaa_customer_reviews = nykaa_customer_reviews.filter(col(\"user_review\").isNotNull())\n","    nykaa_customer_reviews = nykaa_customer_reviews.withColumn(\"review_length\", length(\"user_review\"))\n","    nykaa_customer_reviews = nykaa_customer_reviews.where(nykaa_customer_reviews.product_title == product_name)\n","\n","    partitions = create_partitions(nykaa_customer_reviews)\n","\n","    # Step 1: Run topic generation\n","    final_topics = generate_topics_from_customer_reviews(partitions, spark)\n","\n","    # Step 2: Collect Final Topics from Broadcast Variable\n","    # final_topics = list(generate_topics_from_customer_reviews.previous_topics)\n","\n","    # Step 3: Collect actual reviews\n","    all_reviews = [row[\"user_review\"] for row in nykaa_customer_reviews.collect() if row[\"user_review\"]]\n","\n","    # Step 4: Coherence Calculation (same as before)\n","    import nltk\n","    nltk.download('punkt', force=True)\n","    nltk.download('stopwords', force=True)\n","    nltk.download('wordnet', force=True)\n","    from nltk.tokenize import word_tokenize\n","    from gensim.corpora import Dictionary\n","    from gensim.models import CoherenceModel\n","    from collections import defaultdict\n","    import re\n","\n","    nltk.download('punkt')\n","    nltk.download('stopwords')\n","\n","    stopwords = set(nltk.corpus.stopwords.words('english'))\n","\n","    from nltk.tokenize import TreebankWordTokenizer\n","    tokenizer = TreebankWordTokenizer()\n","\n","    def preprocess(text):\n","        return [w.lower() for w in tokenizer.tokenize(text) if w.isalpha() and w.lower() not in stopwords]\n","\n","    tokenized_reviews = [preprocess(review) for review in all_reviews]\n","\n","    topic_to_reviews = defaultdict(list)\n","\n","    for topic in final_topics:\n","        topic_words = topic.lower().split()\n","        pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(w) for w in topic_words) + r')\\b')\n","        for review_text, tokens in zip(all_reviews, tokenized_reviews):\n","            if pattern.search(' '.join(tokens)):\n","                topic_to_reviews[topic].append(tokens)\n","\n","    coherence_scores = {}\n","\n","    for topic, docs in topic_to_reviews.items():\n","        if len(docs) < 2:\n","            print(f\"Skipping topic '{topic}' (not enough matching reviews)\")\n","            continue\n","\n","        dictionary = Dictionary(docs)\n","        corpus = [dictionary.doc2bow(doc) for doc in docs]\n","        all_words = [word for doc in docs for word in doc]\n","        word_freq = nltk.FreqDist(all_words)\n","        top_words = [w for w, _ in word_freq.most_common(10)]\n","\n","        coherence_model = CoherenceModel(\n","            topics=[top_words],\n","            texts=docs,\n","            dictionary=dictionary,\n","            coherence='c_v'\n","        )\n","        coherence_scores[topic] = coherence_model.get_coherence()\n","\n","    print(\"\\nFinal Coherence Scores:\")\n","    for topic, score in coherence_scores.items():\n","        print(f\"{topic}: {score:.4f}\")"],"metadata":{"id":"puQQzPygsQIY"},"execution_count":null,"outputs":[]}]}