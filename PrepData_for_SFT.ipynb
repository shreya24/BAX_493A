{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3NQ7UJVNHrpWWfVDxdJri"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"kQVvcps3QDPz","executionInfo":{"status":"ok","timestamp":1754435800967,"user_tz":420,"elapsed":3,"user":{"displayName":"Shreya Chandra","userId":"16938757779441472357"}}},"outputs":[],"source":["def PrepData_for_SFT(tokenizer):\n","  \"\"\"\n","  Prepares the Amazon Beauty Q&A dataset for supervised fine-tuning (SFT) of a language model.\n","\n","  Steps:\n","  1. Loads and parses a CSV containing product-related Q&A data (`qa_Beauty.csv`).\n","  2. Loads and parses a corresponding metadata CSV (`meta_Beauty.csv`) to extract product titles and image URLs.\n","  3. Merges the Q&A data with product metadata using the common `asin` key.\n","  4. Constructs a conversational format combining product title, question, and answer.\n","  5. Standardizes the data into a ShareGPT-style format using `standardize_custom_format` and `standardize_sharegpt`.\n","  6. Converts the processed data into a HuggingFace `Dataset`.\n","  7. Loads a quantized, instruction-tuned LLM (`Qwen2.5-1.5B-Instruct`) using Unsloth with a custom system prompt focused on beauty products.\n","  8. Applies a formatting function (`formatting_prompts_func`) to wrap the data in prompt-response format suitable for training.\n","  9. Limits the dataset to 500 examples (due to Colab resource constraints).\n","\n","  Returns:\n","  A processed and formatted dataset (up to 500 samples) ready for fine-tuning the LLM.\n","  \"\"\"\n","  # Source: https://cseweb.ucsd.edu/~jmcauley/datasets/amazon/links.html\n","  # Downloaded the dataset for Beauty, \t5-core (198,502 reviews).\n","  # downloaded the json file, opened with Excel and saved as a csv\n","  beauty_qa = pd.read_csv('/content/sample_data/qa_Beauty.csv', names=[\"conversation\"])\n","\n","  beauty_qa[\"conversation\"] = beauty_qa[\"conversation\"].apply(ast.literal_eval)\n","  df_qa_expanded = beauty_qa[\"conversation\"].apply(pd.Series)\n","  print(df_qa_expanded.head(3))\n","\n","  # This meta data contains information about the name of the product the 'asin' in the beauty_qa dataset corresponded to.\n","  # Hence, left-joining 'title' from beauty_meta_data\n","  # Source: https://cseweb.ucsd.edu/~jmcauley/datasets/amazon/links.html\n","  # Downloaded the dataset for Beauty, \tmetadata (259,204 products)\n","  # downloaded the json file, opened with Excel and saved as a csv\n","  beauty_meta_data = pd.read_csv(\"/content/sample_data/meta_Beauty.csv\", names=[\"metadata\"],on_bad_lines='skip')\n","  # beauty_meta_data = pd.read_json(\"/content/sample_data/meta_Beauty.csv\", lines=True)\n","  pd.set_option('display.max_colwidth', None)\n","  print(beauty_meta_data.head(3))\n","\n","  beauty_meta_data[\"metadata\"] = beauty_meta_data[\"metadata\"].apply(ast.literal_eval)\n","  beauty_meta_data_expanded = beauty_meta_data[\"metadata\"].apply(pd.Series)\n","  # print(beauty_meta_data_expanded.head(3))\n","\n","  beauty_meta_data_expanded = beauty_meta_data_expanded[['asin', 'title', 'imUrl']]\n","  print(beauty_meta_data_expanded.head(3))\n","  beauty_qa_merged = pd.merge(df_qa_expanded, beauty_meta_data_expanded, on = 'asin', how = 'left')\n","  beauty_qa_merged = beauty_qa_merged[['asin', 'title', 'question', 'answer']]\n","  print(beauty_qa_merged.head(3))\n","\n","  beauty_qa_merged = beauty_qa_merged.assign(conversation = \"'question': \" + beauty_qa_merged.title.astype(str) + '. ' + \\\n","  beauty_qa_merged.question.astype(str) + \"'answer': \" + beauty_qa_merged.answer.astype(str))\n","  print(beauty_qa_merged.head(3))\n","\n","  beauty_qa_merged[\"standardized\"] = beauty_qa_merged[\"conversation\"].apply(standardize_custom_format)\n","  print(beauty_qa_merged[\"standardized\"].head(3))\n","\n","  beauty_qa_standardized = Dataset.from_pandas(beauty_qa_merged[\"standardized\"].to_frame())\n","\n","  beauty_qa_standardized = standardize_sharegpt(beauty_qa_standardized)\n","\n","  # Quantize the model, fine tune it on a maximum of 500 examples from your train set\n","  STANDARD_SYSTEM_PROMPT = \"You are a helpful AI assistant specialized in beauty and cosmetics. User will mention beauty product name and then ask a related question. Provide a clear and accurate answer.\"\n","\n","  tokenizer = get_chat_template(\n","      tokenizer,\n","      chat_template = \"qwen-2.5\",\n","  ) # applies correct model-specific chat formating rules\n","\n","  beauty_qa_standardizedV2 = beauty_qa_standardized.map(formatting_prompts_func, batched = True, fn_kwargs={\"STANDARD_SYSTEM_PROMPT\": STANDARD_SYSTEM_PROMPT, \"tokenizer\": tokenizer})\n","  LIMIT = 500 #limiting as we are on the free version. I tried with 1000 rows, google colab kernel crashed\n","  beauty_qa_standardizedV2 = beauty_qa_standardizedV2.take(LIMIT)\n","  return beauty_qa_standardizedV2"]}]}